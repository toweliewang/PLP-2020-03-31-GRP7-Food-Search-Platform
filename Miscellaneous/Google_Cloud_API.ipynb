{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Hello, world!\n",
      "Sentiment: 0.30000001192092896, 0.30000001192092896\n"
     ]
    }
   ],
   "source": [
    "# Imports the Google Cloud client library\n",
    "from google.cloud import language\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types\n",
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"nlp-api-267601-0ee50e9d4189.json\"\n",
    "\n",
    "# Instantiates a client\n",
    "client = language.LanguageServiceClient()\n",
    "\n",
    "# The text to analyze\n",
    "text = u'Hello, world!'\n",
    "document = types.Document(\n",
    "    content=text,\n",
    "    type=enums.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "# Detects the sentiment of the text\n",
    "sentiment = client.analyze_sentiment(document=document).document_sentiment\n",
    "\n",
    "print('Text: {}'.format(text))\n",
    "print('Sentiment: {}, {}'.format(sentiment.score, sentiment.magnitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import language_v1\n",
    "from google.cloud.language_v1 import enums\n",
    "\n",
    "\n",
    "def sample_analyze_entity_sentiment(text_content):\n",
    "    \"\"\"\n",
    "    Analyzing Entity Sentiment in a String\n",
    "\n",
    "    Args:\n",
    "      text_content The text content to analyze\n",
    "    \"\"\"\n",
    "\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "\n",
    "    # text_content = 'Grapes are good. Bananas are bad.'\n",
    "\n",
    "    # Available types: PLAIN_TEXT, HTML\n",
    "    type_ = enums.Document.Type.PLAIN_TEXT\n",
    "\n",
    "    # Optional. If not specified, the language is automatically detected.\n",
    "    # For list of supported languages:\n",
    "    # https://cloud.google.com/natural-language/docs/languages\n",
    "    language = \"en\"\n",
    "    document = {\"content\": text_content, \"type\": type_, \"language\": language}\n",
    "\n",
    "    # Available values: NONE, UTF8, UTF16, UTF32\n",
    "    encoding_type = enums.EncodingType.UTF8\n",
    "\n",
    "    response = client.analyze_entity_sentiment(document, encoding_type=encoding_type)\n",
    "    # Loop through entitites returned from the API\n",
    "    for entity in response.entities:\n",
    "        print('----------------------------------------------------------')\n",
    "        print(u\"Representative name for the entity: {}\".format(entity.name))\n",
    "        # Get entity type, e.g. PERSON, LOCATION, ADDRESS, NUMBER, et al\n",
    "        print(u\"Entity type: {}\".format(enums.Entity.Type(entity.type).name))\n",
    "        # Get the salience score associated with the entity in the [0, 1.0] range\n",
    "        print(u\"Salience score: {}\".format(entity.salience))\n",
    "        # Get the aggregate sentiment expressed for this entity in the provided document.\n",
    "        sentiment = entity.sentiment\n",
    "        print(u\"Entity sentiment score: {}\".format(sentiment.score))\n",
    "        print(u\"Entity sentiment magnitude: {}\".format(sentiment.magnitude))\n",
    "        # Loop over the metadata associated with entity. For many known entities,\n",
    "        # the metadata is a Wikipedia URL (wikipedia_url) and Knowledge Graph MID (mid).\n",
    "        # Some entity types may have additional metadata, e.g. ADDRESS entities\n",
    "        # may have metadata for the address street_name, postal_code, et al.\n",
    "        for metadata_name, metadata_value in entity.metadata.items():\n",
    "            print(u\"{} = {}\".format(metadata_name, metadata_value))\n",
    "\n",
    "        # Loop over the mentions of this entity in the input document.\n",
    "        # The API currently supports proper noun mentions.\n",
    "        for mention in entity.mentions:\n",
    "            print(u\"Mention text: {}\".format(mention.text.content))\n",
    "            # Get the mention type, e.g. PROPER for proper noun\n",
    "            print(\n",
    "                u\"Mention type: {}\".format(enums.EntityMention.Type(mention.type).name)\n",
    "            )\n",
    "\n",
    "    # Get the language of the text, which will be the same as\n",
    "    # the language specified in the request or, if not specified,\n",
    "    # the automatically-detected language.\n",
    "    print(u\"Language of the text: {}\".format(response.language))\n",
    "    \n",
    "def sample_analyze_sentiment(text_content):\n",
    "    \"\"\"\n",
    "    Analyzing Sentiment in a String\n",
    "\n",
    "    Args:\n",
    "      text_content The text content to analyze\n",
    "    \"\"\"\n",
    "\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "    \n",
    "    # Available types: PLAIN_TEXT, HTML\n",
    "    type_ = enums.Document.Type.PLAIN_TEXT\n",
    "\n",
    "    # Optional. If not specified, the language is automatically detected.\n",
    "    # For list of supported languages:\n",
    "    # https://cloud.google.com/natural-language/docs/languages\n",
    "    language = \"en\"\n",
    "    document = {\"content\": text_content, \"type\": type_, \"language\": language}\n",
    "\n",
    "    # Available values: NONE, UTF8, UTF16, UTF32\n",
    "    encoding_type = enums.EncodingType.UTF8\n",
    "\n",
    "    response = client.analyze_sentiment(document, encoding_type=encoding_type)\n",
    "    # Get overall sentiment of the input document\n",
    "    print(u\"Document sentiment score: {}\".format(response.document_sentiment.score))\n",
    "    print(\n",
    "        u\"Document sentiment magnitude: {}\".format(\n",
    "            response.document_sentiment.magnitude\n",
    "        )\n",
    "    )\n",
    "    # Get sentiment for all sentences in the document\n",
    "    for sentence in response.sentences:\n",
    "        print('-------------------------')\n",
    "        print(u\"Sentence text: {}\".format(sentence.text.content))\n",
    "        print(u\"Sentence sentiment score: {}\".format(sentence.sentiment.score))\n",
    "        print(u\"Sentence sentiment magnitude: {}\".format(sentence.sentiment.magnitude))\n",
    "\n",
    "    # Get the language of the text, which will be the same as\n",
    "    # the language specified in the request or, if not specified,\n",
    "    # the automatically-detected language.\n",
    "    print(u\"Language of the text: {}\".format(response.language))\n",
    "    \n",
    "def sample_classify_text(text_content):\n",
    "    \"\"\"\n",
    "    Classifying Content in a String\n",
    "\n",
    "    Args:\n",
    "      text_content The text content to analyze. Must include at least 20 words.\n",
    "    \"\"\"\n",
    "\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "\n",
    "    # text_content = 'That actor on TV makes movies in Hollywood and also stars in a variety of popular new TV shows.'\n",
    "\n",
    "    # Available types: PLAIN_TEXT, HTML\n",
    "    type_ = enums.Document.Type.PLAIN_TEXT\n",
    "\n",
    "    # Optional. If not specified, the language is automatically detected.\n",
    "    # For list of supported languages:\n",
    "    # https://cloud.google.com/natural-language/docs/languages\n",
    "    language = \"en\"\n",
    "    document = {\"content\": text_content, \"type\": type_, \"language\": language}\n",
    "\n",
    "    response = client.classify_text(document)\n",
    "    # Loop through classified categories returned from the API\n",
    "    for category in response.categories:\n",
    "        # Get the name of the category representing the document.\n",
    "        # See the predefined taxonomy of categories:\n",
    "        # https://cloud.google.com/natural-language/docs/categories\n",
    "        print(u\"Category name: {}\".format(category.name))\n",
    "        # Get the confidence. Number representing how certain the classifier\n",
    "        # is that this category represents the provided text.\n",
    "        print(u\"Confidence: {}\".format(category.confidence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_content = '\"My companion and I went to Living Kitchen on an impulse and am very happy to say it was delicious and worth it! My companion got the Arugula Harvest salad and I got the Pad Thai. The Arugula Harvest salad was very tasty and all of the components came together well. The Pad Thai was also very flavorful and had an awesome sauce which had a good afterburn to it. I would highly recommend coming here to try the food vegan, vegetarian, or otherwise.'\n",
    "text_content = 'the price was costly, but it was worth it.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_analyze_entity_sentiment(text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category name: /Food & Drink/Cooking & Recipes\n",
      "Confidence: 0.699999988079071\n"
     ]
    }
   ],
   "source": [
    "# sample_classify_text(text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document sentiment score: 0.699999988079071\n",
      "Document sentiment magnitude: 0.699999988079071\n",
      "-------------------------\n",
      "Sentence text: the price was costly, but it was worth it.\n",
      "Sentence sentiment score: 0.699999988079071\n",
      "Sentence sentiment magnitude: 0.699999988079071\n",
      "Language of the text: en\n"
     ]
    }
   ],
   "source": [
    "sample_analyze_sentiment(text_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
